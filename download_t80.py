#!/usr/bin/env python3
"""
Download and process Lc0 T80 training data.

The T80 dataset contains positions from Leela Chess Zero's Training Run 1,
generated by a ~3200 ELO engine. This is the gold standard for AlphaZero-style
supervised learning.

Key advantages over Lichess evaluated positions:
- Soft policy targets (MCTS visit distribution, not just best move)
- Positions from strong self-play (consistent quality)
- Native binary format (fast loading, no parsing)
- Higher quality training signal

Data source: https://storage.lczero.org/files/training_data/test80/
Format: V6 (8356 bytes per position)

Usage:
    # Download to a volume first (cheap CPU instance)
    python download_t80.py --output ./data/t80 --num-files 50

    # Then train on expensive GPU
    python train.py --data ./data/t80
"""

import os
import sys
import gzip
import struct
import tarfile
import tempfile
import argparse
import requests
import numpy as np
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from typing import List, Tuple, Optional
import multiprocessing as mp
from io import BytesIO
import re
from datetime import datetime

# Lc0 V6 format constants
V6_STRUCT_SIZE = 8356
V6_VERSION = 6
NUM_POLICY_MOVES = 1858  # Lc0's policy size

# Lc0 move encoding - maps (from_sq, to_sq, promo) to Lc0 policy index
# This is computed at module load time
LC0_MOVE_TO_IDX = {}
LC0_IDX_TO_MOVE = {}

def _init_lc0_move_tables():
    """Initialize Lc0's move encoding tables (1858 moves)"""
    global LC0_MOVE_TO_IDX, LC0_IDX_TO_MOVE

    idx = 0

    # Queen moves (including rook/bishop): 56 per square (8 directions * 7 distances)
    # But only for valid destinations
    for from_sq in range(64):
        from_rank = from_sq // 8
        from_file = from_sq % 8

        # 8 directions: N, NE, E, SE, S, SW, W, NW
        directions = [
            (1, 0), (1, 1), (0, 1), (-1, 1),
            (-1, 0), (-1, -1), (0, -1), (1, -1)
        ]

        for dir_idx, (dr, df) in enumerate(directions):
            for dist in range(1, 8):
                to_rank = from_rank + dr * dist
                to_file = from_file + df * dist
                if 0 <= to_rank < 8 and 0 <= to_file < 8:
                    to_sq = to_rank * 8 + to_file
                    LC0_MOVE_TO_IDX[(from_sq, to_sq, None)] = idx
                    LC0_IDX_TO_MOVE[idx] = (from_sq, to_sq, None)
                    idx += 1

    # Knight moves: 8 per square (but only valid ones)
    knight_deltas = [
        (2, 1), (2, -1), (-2, 1), (-2, -1),
        (1, 2), (1, -2), (-1, 2), (-1, -2)
    ]
    for from_sq in range(64):
        from_rank = from_sq // 8
        from_file = from_sq % 8
        for dr, df in knight_deltas:
            to_rank = from_rank + dr
            to_file = from_file + df
            if 0 <= to_rank < 8 and 0 <= to_file < 8:
                to_sq = to_rank * 8 + to_file
                key = (from_sq, to_sq, None)
                if key not in LC0_MOVE_TO_IDX:
                    LC0_MOVE_TO_IDX[key] = idx
                    LC0_IDX_TO_MOVE[idx] = key
                    idx += 1

    # Underpromotions (knight, bishop, rook - queen is default)
    # Pawns promote from rank 6 (white) or rank 1 (black), viewed as rank 6 after flip
    KNIGHT, BISHOP, ROOK = 2, 3, 4
    for promo in [KNIGHT, BISHOP, ROOK]:
        for from_file in range(8):
            from_sq = 6 * 8 + from_file  # Rank 6 (0-indexed)
            # Straight promotion
            to_sq = 7 * 8 + from_file
            LC0_MOVE_TO_IDX[(from_sq, to_sq, promo)] = idx
            LC0_IDX_TO_MOVE[idx] = (from_sq, to_sq, promo)
            idx += 1
            # Capture left
            if from_file > 0:
                to_sq = 7 * 8 + from_file - 1
                LC0_MOVE_TO_IDX[(from_sq, to_sq, promo)] = idx
                LC0_IDX_TO_MOVE[idx] = (from_sq, to_sq, promo)
                idx += 1
            # Capture right
            if from_file < 7:
                to_sq = 7 * 8 + from_file + 1
                LC0_MOVE_TO_IDX[(from_sq, to_sq, promo)] = idx
                LC0_IDX_TO_MOVE[idx] = (from_sq, to_sq, promo)
                idx += 1

    print(f"Initialized Lc0 move tables: {idx} moves")

_init_lc0_move_tables()


def parse_v6_record(data: bytes) -> Optional[dict]:
    """
    Parse a single V6 training record (8356 bytes).

    Returns dict with:
        - planes: 104 x uint64 bitboards
        - probabilities: 1858 floats (MCTS visit distribution)
        - result_q: game outcome [-1, 1]
        - result_d: draw probability
        - best_q: position evaluation
        - castling: (us_ooo, us_oo, them_ooo, them_oo)
        - side_to_move: 0 or 1
        - rule50: fifty-move counter
    """
    if len(data) != V6_STRUCT_SIZE:
        return None

    offset = 0

    # Version and input_format (8 bytes)
    version, input_format = struct.unpack_from('<II', data, offset)
    offset += 8

    if version != V6_VERSION:
        return None

    # Probabilities: 1858 floats (7432 bytes)
    probabilities = np.frombuffer(data, dtype=np.float32, count=1858, offset=offset)
    offset += 1858 * 4

    # Planes: 104 uint64 (832 bytes) - raw bitboards
    planes = np.frombuffer(data, dtype=np.uint64, count=104, offset=offset)
    offset += 104 * 8

    # Castling and other flags (8 bytes)
    castling_us_ooo = data[offset]
    castling_us_oo = data[offset + 1]
    castling_them_ooo = data[offset + 2]
    castling_them_oo = data[offset + 3]
    side_to_move_or_ep = data[offset + 4]
    rule50 = data[offset + 5]
    invariance_info = data[offset + 6]
    dummy = data[offset + 7]
    offset += 8

    # Q-values and other floats (44 bytes)
    floats = struct.unpack_from('<11f', data, offset)
    root_q, best_q, root_d, best_d, root_m, best_m, plies_left = floats[:7]
    result_q, result_d, played_q, played_d = floats[7:11]
    offset += 44

    # More floats (12 bytes)
    played_m, orig_q, orig_d = struct.unpack_from('<3f', data, offset)
    offset += 12

    # orig_m, visits, played_idx, best_idx, policy_kld, reserved (20 bytes)
    orig_m, = struct.unpack_from('<f', data, offset)
    offset += 4
    visits, = struct.unpack_from('<I', data, offset)
    offset += 4
    played_idx, best_idx = struct.unpack_from('<HH', data, offset)
    offset += 4
    policy_kld, = struct.unpack_from('<f', data, offset)
    offset += 4
    reserved, = struct.unpack_from('<I', data, offset)

    return {
        'probabilities': probabilities.copy(),
        'planes': planes.copy(),
        'result_q': result_q,
        'result_d': result_d,
        'best_q': best_q,
        'castling': (castling_us_ooo, castling_us_oo, castling_them_ooo, castling_them_oo),
        'side_to_move': side_to_move_or_ep & 1,
        'rule50': rule50,
        'best_idx': best_idx,
        'played_idx': played_idx,
        'visits': visits,
    }


def lc0_planes_to_board(planes: np.ndarray, castling: tuple,
                         side_to_move: int, rule50: int) -> np.ndarray:
    """
    Convert Lc0's 104x64-bit planes to our 18x8x8 format.

    Lc0 plane layout (first 13 planes are current position):
        0: Our pawns
        1: Our knights
        2: Our bishops
        3: Our rooks
        4: Our queens
        5: Our kings
        6: Their pawns
        7: Their knights
        8: Their bishops
        9: Their rooks
        10: Their queens
        11: Their kings
        12: Repetition count (we ignore)

    IMPORTANT: Lc0 planes are ALWAYS from the side-to-move's perspective.
    Our encoding is always from White's perspective.
    So when black is to move, we need to flip the board vertically and
    swap "our" pieces (0-5) with "their" pieces (6-11).

    Remaining planes are history (we ignore for now).
    """
    board = np.zeros((18, 8, 8), dtype=np.float32)

    # When black to move, Lc0's "our" is black and "their" is white
    # We need to swap and flip vertically
    is_black_to_move = (side_to_move == 1)

    # Extract piece bitboards (first 12 planes)
    for lc0_plane_idx in range(12):
        bitboard = planes[lc0_plane_idx]

        # Determine which plane this maps to in our encoding
        if is_black_to_move:
            # Swap: Lc0's "our" (0-5) -> our black (6-11)
            #       Lc0's "their" (6-11) -> our white (0-5)
            if lc0_plane_idx < 6:
                our_plane_idx = lc0_plane_idx + 6  # Black pieces
            else:
                our_plane_idx = lc0_plane_idx - 6  # White pieces
        else:
            our_plane_idx = lc0_plane_idx

        for sq in range(64):
            if bitboard & (1 << sq):
                rank = sq // 8
                file = sq % 8
                # Flip vertically when black to move
                if is_black_to_move:
                    rank = 7 - rank
                board[our_plane_idx, rank, file] = 1.0

    # Side to move (plane 12) - always set for white to move
    if not is_black_to_move:
        board[12, :, :] = 1.0

    # Castling rights (planes 13-16)
    # Lc0 castling is from side-to-move perspective, we need white's perspective
    us_ooo, us_oo, them_ooo, them_oo = castling
    if is_black_to_move:
        # Swap: "us" is black, "them" is white
        if them_oo:  # White kingside
            board[13, :, :] = 1.0
        if them_ooo:  # White queenside
            board[14, :, :] = 1.0
        if us_oo:  # Black kingside
            board[15, :, :] = 1.0
        if us_ooo:  # Black queenside
            board[16, :, :] = 1.0
    else:
        if us_oo:  # White kingside
            board[13, :, :] = 1.0
        if us_ooo:  # White queenside
            board[14, :, :] = 1.0
        if them_oo:  # Black kingside
            board[15, :, :] = 1.0
        if them_ooo:  # Black queenside
            board[16, :, :] = 1.0

    # En passant - extracted from planes if available
    # For simplicity, we'll skip en passant in initial version
    # (plane 17 stays zeros)

    return board


def process_chunk_file(chunk_path: str) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    Process a single .chunk.gz file and extract training data.

    Returns:
        boards: (N, 18, 8, 8) float32
        policies: (N, 1858) float32 - soft targets!
        values: (N,) float32
    """
    boards_list = []
    policies_list = []
    values_list = []

    with gzip.open(chunk_path, 'rb') as f:
        data = f.read()

    num_records = len(data) // V6_STRUCT_SIZE

    for i in range(num_records):
        record_data = data[i * V6_STRUCT_SIZE:(i + 1) * V6_STRUCT_SIZE]
        record = parse_v6_record(record_data)

        if record is None:
            continue

        # Convert to our format
        board = lc0_planes_to_board(
            record['planes'],
            record['castling'],
            record['side_to_move'],
            record['rule50']
        )

        # Use soft policy targets (the key advantage of T80!)
        policy = record['probabilities']

        # Normalize policy to sum to 1
        policy_sum = policy.sum()
        if policy_sum > 0:
            policy = policy / policy_sum
        else:
            continue  # Skip positions with no policy

        # Value from position evaluation (best_q) or game result
        # best_q is the MCTS-backed evaluation, result_q is game outcome
        # We use best_q for position evaluation (more stable than game result)
        # NOTE: best_q is from side-to-move's perspective, but our encoding
        # is always from White's perspective, so flip for black
        value = record['best_q']
        if record['side_to_move'] == 1:  # Black to move
            value = -value

        # Clamp to [-1, 1]
        value = max(-1.0, min(1.0, value))

        boards_list.append(board)
        policies_list.append(policy)
        values_list.append(value)

    if not boards_list:
        return None, None, None

    return (
        np.array(boards_list, dtype=np.float32),
        np.array(policies_list, dtype=np.float32),
        np.array(values_list, dtype=np.float32)
    )


def download_file(url: str, output_path: str,
                  chunk_size: int = 8192,
                  show_progress: bool = True) -> bool:
    """Download a file with progress bar"""
    try:
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()

        total_size = int(response.headers.get('content-length', 0))

        with open(output_path, 'wb') as f:
            if show_progress and total_size:
                pbar = tqdm(total=total_size, unit='B', unit_scale=True,
                           desc=os.path.basename(output_path))

            for chunk in response.iter_content(chunk_size=chunk_size):
                f.write(chunk)
                if show_progress and total_size:
                    pbar.update(len(chunk))

            if show_progress and total_size:
                pbar.close()

        return True
    except Exception as e:
        print(f"Error downloading {url}: {e}")
        return False


def list_t80_files(base_url: str = "https://storage.lczero.org/files/training_data/test80/") -> List[str]:
    """List available T80 training files"""
    try:
        response = requests.get(base_url, timeout=30)
        response.raise_for_status()

        # Parse HTML to find .tar files
        files = re.findall(r'training-run1-test80-\d{8}-\d{4}\.tar', response.text)
        return sorted(set(files))
    except Exception as e:
        print(f"Error listing files: {e}")
        return []


def download_single_file(args):
    """Download a single file - for parallel downloading"""
    url, tar_path, file_idx, total_files = args
    filename = os.path.basename(tar_path)

    if os.path.exists(tar_path):
        return tar_path, True, f"[{file_idx+1}/{total_files}] {filename} (cached)"

    try:
        response = requests.get(url, stream=True, timeout=60)
        response.raise_for_status()

        total_size = int(response.headers.get('content-length', 0))

        with open(tar_path, 'wb') as f:
            downloaded = 0
            for chunk in response.iter_content(chunk_size=65536):
                f.write(chunk)
                downloaded += len(chunk)

        return tar_path, True, f"[{file_idx+1}/{total_files}] {filename} ({total_size/1e6:.1f}MB)"
    except Exception as e:
        return tar_path, False, f"[{file_idx+1}/{total_files}] {filename} FAILED: {e}"


def download_and_process_t80(
    output_dir: str = "./data/t80",
    num_files: int = 10,
    num_positions: int = None,
    start_date: str = None,
    workers: int = 4,
    keep_tar: bool = False,
):
    """
    Download and process T80 training data.

    Args:
        output_dir: Where to save processed .npz files
        num_files: Number of .tar files to download
        num_positions: Stop after this many positions (None = no limit)
        start_date: Start from this date (YYYYMMDD format)
        workers: Number of parallel workers for processing AND downloading
        keep_tar: Keep downloaded .tar files
    """
    os.makedirs(output_dir, exist_ok=True)

    base_url = "https://storage.lczero.org/files/training_data/test80/"

    print(f"\n{'='*60}")
    print("DOWNLOADING LC0 T80 TRAINING DATA")
    print(f"{'='*60}")
    print(f"Source: {base_url}")
    print(f"Output: {output_dir}")
    print(f"Files to download: {num_files}")
    print(f"Workers: {workers} (parallel downloads + parallel processing)")
    print(f"{'='*60}\n")

    # Get list of available files
    print("Fetching file list...")
    files = list_t80_files(base_url)

    if not files:
        print("ERROR: Could not fetch file list from storage.lczero.org")
        return

    print(f"Found {len(files)} T80 training files")

    # Filter by date if specified
    if start_date:
        files = [f for f in files if start_date in f or f > f"training-run1-test80-{start_date}"]

    # Take requested number
    files = files[:num_files]

    print(f"Will download {len(files)} files")

    total_positions = 0
    chunk_idx = 0
    all_boards = []
    all_policies = []
    all_values = []

    # PHASE 1: Download all files in parallel (much faster!)
    print(f"\n--- PHASE 1: Parallel Download ({min(workers, len(files))} concurrent) ---")
    download_args = [
        (base_url + filename, os.path.join(output_dir, filename), idx, len(files))
        for idx, filename in enumerate(files)
    ]

    downloaded_files = []
    with ThreadPoolExecutor(max_workers=min(workers, len(files))) as executor:
        for tar_path, success, msg in tqdm(
            executor.map(download_single_file, download_args),
            total=len(files),
            desc="Downloading"
        ):
            print(f"  {msg}")
            if success:
                downloaded_files.append(tar_path)

    print(f"\nDownloaded {len(downloaded_files)}/{len(files)} files")

    # PHASE 2: Process downloaded files
    print(f"\n--- PHASE 2: Process Files ({workers} workers) ---")
    for file_idx, tar_path in enumerate(downloaded_files):
        filename = os.path.basename(tar_path)
        print(f"\n[{file_idx + 1}/{len(downloaded_files)}] Processing {filename}...")

        try:
            with tarfile.open(tar_path, 'r') as tar:
                members = [m for m in tar.getmembers() if m.name.endswith('.gz')]

                # Extract all chunks to temp files for parallel processing
                temp_files = []
                for member in members:
                    chunk_data = tar.extractfile(member).read()
                    tmp = tempfile.NamedTemporaryFile(suffix='.gz', delete=False)
                    tmp.write(chunk_data)
                    tmp.close()
                    temp_files.append(tmp.name)

                # Process chunks in parallel using ProcessPoolExecutor
                try:
                    with ProcessPoolExecutor(max_workers=workers) as executor:
                        results = list(tqdm(
                            executor.map(process_chunk_file, temp_files),
                            total=len(temp_files),
                            desc="Processing chunks"
                        ))

                    for boards, policies, values in results:
                        if boards is not None:
                            all_boards.append(boards)
                            all_policies.append(policies)
                            all_values.append(values)
                            total_positions += len(boards)

                        # Check position limit
                        if num_positions and total_positions >= num_positions:
                            break
                finally:
                    # Clean up temp files
                    for tmp_path in temp_files:
                        try:
                            os.unlink(tmp_path)
                        except:
                            pass

                # Save chunk when we have enough
                current_size = sum(len(b) for b in all_boards)
                if current_size >= 1_000_000:  # Save every 1M positions
                    chunk_name = f"chunk_{chunk_idx:04d}.npz"
                    chunk_path = os.path.join(output_dir, chunk_name)

                    np.savez(
                        chunk_path,
                        boards=np.concatenate(all_boards),
                        policies=np.concatenate(all_policies),
                        values=np.concatenate(all_values),
                    )

                    print(f"\n  Saved {chunk_path} ({current_size:,} positions)")

                    chunk_idx += 1
                    all_boards = []
                    all_policies = []
                    all_values = []

            # Remove tar file if not keeping
            if not keep_tar and os.path.exists(tar_path):
                os.unlink(tar_path)

        except Exception as e:
            print(f"Error processing {filename}: {e}")
            continue

        # Check position limit
        if num_positions and total_positions >= num_positions:
            print(f"\nReached position limit: {num_positions:,}")
            break

    # Save remaining data
    if all_boards:
        chunk_name = f"chunk_{chunk_idx:04d}.npz"
        chunk_path = os.path.join(output_dir, chunk_name)

        np.savez(
            chunk_path,
            boards=np.concatenate(all_boards),
            policies=np.concatenate(all_policies),
            values=np.concatenate(all_values),
        )

        print(f"\n  Saved {chunk_path} ({sum(len(b) for b in all_boards):,} positions)")

    print(f"\n{'='*60}")
    print("DOWNLOAD COMPLETE")
    print(f"{'='*60}")
    print(f"Total positions: {total_positions:,}")
    print(f"Chunks saved: {chunk_idx + 1}")
    print(f"Output directory: {output_dir}")
    print(f"\nTo train:")
    print(f"  python train.py --data {output_dir} --policy-size 1858")


def verify_t80_dataset(data_dir: str):
    """Verify the T80 dataset"""
    import glob

    files = sorted(glob.glob(os.path.join(data_dir, "chunk_*.npz")))

    if not files:
        print(f"No .npz files found in {data_dir}")
        return

    print(f"\nVerifying T80 dataset in {data_dir}")
    print(f"Found {len(files)} chunk files")

    data = np.load(files[0])
    boards = data['boards']
    policies = data['policies']
    values = data['values']

    print(f"\nFirst chunk stats:")
    print(f"  Boards shape: {boards.shape}")
    print(f"  Policies shape: {policies.shape}")
    print(f"  Values shape: {values.shape}")

    print(f"\nValue distribution:")
    print(f"  Min: {values.min():.3f}")
    print(f"  Max: {values.max():.3f}")
    print(f"  Mean: {values.mean():.3f}")
    print(f"  Std: {values.std():.3f}")

    print(f"\nPolicy stats (soft targets):")
    print(f"  Mean entropy: {-(policies * np.log(policies + 1e-10)).sum(axis=1).mean():.3f}")
    print(f"  Mean max prob: {policies.max(axis=1).mean():.3f}")

    # Count value distribution
    winning = np.sum(values > 0.5)
    equal = np.sum((values >= -0.5) & (values <= 0.5))
    losing = np.sum(values < -0.5)

    print(f"\nValue breakdown:")
    print(f"  Winning (>0.5): {winning} ({100*winning/len(values):.1f}%)")
    print(f"  Equal (-0.5 to 0.5): {equal} ({100*equal/len(values):.1f}%)")
    print(f"  Losing (<-0.5): {losing} ({100*losing/len(values):.1f}%)")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Download and process Lc0 T80 training data",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Download 10 files (~10-20M positions)
    python download_t80.py --output ./data/t80 --num-files 10

    # Download specific number of positions
    python download_t80.py --output ./data/t80 --positions 50000000

    # Verify downloaded data
    python download_t80.py --output ./data/t80 --verify
"""
    )

    parser.add_argument("--output", type=str, default="./data/t80",
                        help="Output directory")
    parser.add_argument("--num-files", type=int, default=10,
                        help="Number of .tar files to download")
    parser.add_argument("--positions", type=int, default=None,
                        help="Stop after this many positions")
    parser.add_argument("--start-date", type=str, default=None,
                        help="Start from date (YYYYMMDD)")
    parser.add_argument("--workers", type=int, default=4,
                        help="Number of parallel workers")
    parser.add_argument("--keep-tar", action="store_true",
                        help="Keep downloaded .tar files")
    parser.add_argument("--verify", action="store_true",
                        help="Verify existing dataset")

    args = parser.parse_args()

    if args.verify:
        verify_t80_dataset(args.output)
    else:
        download_and_process_t80(
            output_dir=args.output,
            num_files=args.num_files,
            num_positions=args.positions,
            start_date=args.start_date,
            workers=args.workers,
            keep_tar=args.keep_tar,
        )
